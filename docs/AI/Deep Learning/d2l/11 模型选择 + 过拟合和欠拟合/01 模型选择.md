# 01 模型选择
## 训练误差和泛化误差
- 训练误差：模型在训练数据上的误差
- 泛化误差：模型在新数据上的误差
- 例子：根据模考成绩来预测未来考试分数
    - 在过去的考试中表现很好（训练误差）不代表未来考试一定会好（泛化误差）
    - 学生 A 通过背书在模考中拿到很好成绩
    - 学生 B 知道答案后面的原因

## 验证数据集和测试数据集
- 验证数据集：一个用于评估模型好坏的数据集
    - 例如拿出 50%的训练数据
    - 不要跟训练数据混在一起（常犯错误）。也就是拿验证数据集来训练模型，从而使得更好的泛化能力。
    - 验证数据集的精度不一定代表在新数据表现良好，因为验证集的精度也可能是通过超参数来调整的。
- 测试数据集：只用一次的数据集
    - 未来的考试
    - 不要拿测试集来调整模型的超参数，甚至跑了几百回拿最高精度的模型来表示 SOTA

## K-则交叉验证
- 在没有足够多数据时使用
- 算法
    - 将训练数据分割成 K 块
    - For i = 1,..., k
        - 使用第 i 块作为验证数据集，其余的作为训练数据集
        - 循环，一直交换验证和训练数据集的块
    - 报告 K 个验证集精度误差做平均
- 常用：K = 5 或 10；极端的情况下是：数据长度为 N，做 N 则交叉验证

## 总结
- 训练数据集：训练模型参数
- 验证数据集：选择模型超参数
- 非大型数据集上通常使用 k-折交叉验证