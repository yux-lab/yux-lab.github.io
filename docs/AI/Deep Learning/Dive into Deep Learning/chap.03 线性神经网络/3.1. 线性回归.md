# 3.1. 线性回归

## 3.1.1. 线性回归的基本元素
线性回归基于几个简单的假设：
假设自变量$\mathbf{x}$和因变量$y$之间的关系是线性的，即$y$可以表示为$\mathbf{x}$中元素的加权和
> 加权和指的是：各个元素与相应权重（系数）的乘积之和

例子：根据房屋面积（平方英尺）和房龄（年）来估算房屋价格（美元）
预测房价模型的准备工作：
数据集/训练集：包括价格、面积和房龄
样本/数据点/数据样本：每行数据；一次房屋交易相对应的数据
标签/目标：试图预测的目标，比如预测房屋价格
特征/协变量：预测所依据的自变量x（面积和房龄）；特征向量

使用$n$来表示数据集中的样本数
对索引为$i$的样本，其输入表示为$\mathbf{x}^{(i)} = [x_1^{(i)}, x_2^{(i)}]^\top$，
其对应的标签是$y^{(i)}$。

### 3.1.1.1. 线性模型
加权和：

$$\mathrm{price} = w_{\mathrm{area}} \cdot \mathrm{area} + w_{\mathrm{age}} \cdot \mathrm{age} + b.$$

w：权重；决定每个特征对预测值的影响
b：偏置/截距。起码有个最低值；当所有特征都取值为0时，预测值应该为多少

上方公式是输入特征的一个 _仿射变换_
[仿射变换 - Wikiwand](https://www.wikiwand.com/zh-hans/%E4%BB%BF%E5%B0%84%E5%8F%98%E6%8D%A2)
> 仿射变换的特点是通过加权和对特征进行_线性变换_，并通过偏置项来进行_平移_（translation）。

给定一个数据集，目标是寻找模型的权重$\mathbf{w}$和偏置$b$，使得根据模型做出的预测大体符合数据里的真实价格。
输出的预测值由输入特征通过*线性模型*的仿射变换决定，仿射变换由所选权重和偏置确定。

$x$表示输入的特征向量，其中$x_1, x_2, ..., x_d$是特征向量的各个维度的取值。当输入包含$d$个特征时，将预测结果$\hat{y}$（通常使用“尖角”符号表示$y$的估计值）表示为：

$$\hat{y} = w_1  x_1 + ... + w_d  x_d + b.$$

将所有特征放到向量$\mathbf{x} \in \mathbb{R}^d$中，并将所有权重放到向量$\mathbf{w} \in \mathbb{R}^d$中，可以用点积形式来简洁地表达模型：

$$\hat{y} = \mathbf{w}^\top \mathbf{x} + b.$$

> 在这个公式中，$\mathbf{w}^\top$表示向量$\mathbf{w}$的转置，表示将$\mathbf{w}$的行向量转换为列向量。$\mathbf{w}^\top \mathbf{x}$表示将特征向量$\mathbf{x}$与权重向量$\mathbf{w}$进行点积运算，即将对应位置的元素相乘并相加得到一个标量值。

在上方公式中，向量$\mathbf{x}$对应于单个数据样本的特征。
用符号表示的矩阵$\mathbf{X} \in \mathbb{R}^{n \times d}$可以很方便地引用我们整个数据集的$n$个样本。
其中，$\mathbf{X}$的每一行是一个样本，每一列是一种特征。

对于特征集合$\mathbf{X}$，预测值$\hat{\mathbf{y}} \in \mathbb{R}^n$可以通过矩阵-向量乘法表示为：

$${\hat{\mathbf{y}}} = \mathbf{X} \mathbf{w} + b$$

> 在这个公式中，$\mathbb{R}$表示实数集，表示矩阵$\mathbf{X}$中的元素是实数。$\mathbf{X} \in \mathbb{R}^{n \times d}$表示矩阵$\mathbf{X}$的维度为$n \times d$，其中$n$表示矩阵的行数，$d$表示矩阵的列数。
> 具体来说，$\mathbf{X}$是一个包含$n$个样本和$d$个特征的矩阵。每一行代表一个样本，每一列代表一个特征。矩阵$\mathbf{X}$的第$(i,j)$个元素表示第$i$个样本的第$j$个特征的取值。


（1）一种模型质量的度量方式； （2）一种能够更新模型以提高模型预测质量的方法。


### 3.1.1.2. 损失函数
_损失函数_（loss function）能够量化目标的 _实际_ 值与 _预测_ 值之间的差距。

#加条公式 平方误差

### 3.1.1.4. 随机梯度下降
_泛化_:找到一组参数，在未见过的数据上实现较低的损失

## 3.1.2. 矢量化加速
**矢量化**：将标量操作转换为向量操作。标量操作是一次处理一个数据元素，而向量操作是一次处理多个数据元素。

**矢量化加速**
矢量化加速是指通过矢量化技术来提高程序的执行速度。由于向量处理器可以一次处理多个数据元素，因此矢量化能够显著减少循环的开销，提高计算效率。

简单来说就是调包numpy来处理数据而不是用内置的像for一样的函数

## 3.1.3. 正态分布与平方损失
假设我们有一个简单的线性回归模型，用于预测房价。我们有一些训练数据，包括房子的面积（特征）和对应的房价（目标值）。我们可以使用平方损失来衡量模型的预测误差，并通过最小化均方误差来优化模型参数。