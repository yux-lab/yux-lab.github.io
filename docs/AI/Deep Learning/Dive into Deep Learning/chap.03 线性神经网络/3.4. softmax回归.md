# 3.4. softmax回归

## 3.4.1. 分类问题
从一个图像分类问题开始。
假设每次输入是一个$2\times2$的灰度图像。
可以用一个标量表示每个像素值，每个图像对应四个特征$x_1, x_2, x_3, x_4$。
> 为什么是四个特征？因为$2\times2$的像素值如：
```plaintext
[ 0.1, 0.2 ]
[ 0.3, 0.4 ]

//将每个图像的像素值展开成一个特征向量：
[ 0.1, 0.2, 0.3, 0.4 ]
```

此外，假设每个图像属于类别“猫”“鸡”和“狗”中的一个。

_独热编码_:一个向量，它的分量和类别一样多。 类别对应的分量设置为1，其他所有分量设置为0。

## 3.4.2. 网络架构
每个输出对应于它自己的仿射函数
[仿射变换 - 维基百科，自由的百科全书 (wikipedia.org)](https://zh.wikipedia.org/wiki/%E4%BB%BF%E5%B0%84%E5%8F%98%E6%8D%A2)
![](images/Pasted%20image%2020240707091730.png)
> 全连接层（Fully Connected Layer）是多层感知器应用在卷积神经网络中的多种组件之一。在深度学习领域中，用于分类任务的卷积神经网络模型的网络结构的最后几层往往是全连接层，用于将从该层之前的几个特征抽取层获得的特征表达向量映射到下一层，或者映射到最终的softmax层。
> 全连接层的主要作用就是将前层（卷积、池化等层）计算得到的特征空间映射样本标记空间。简单的说就是将特征表示整合成一个值，其优点在于减少特征位置对于分类结果的影响，提高了整个网络的鲁棒性。

[3.6. softmax回归的从零开始实现 — 动手学深度学习 2.0.0 documentation (d2l.ai)](https://zh.d2l.ai/chapter_linear-networks/softmax-regression-scratch.html)